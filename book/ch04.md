# Chapter 4: Creating AI Analyst Personas

> "The test of a first-rate intelligence is the ability to hold two opposed ideas in mind at the same time and still retain the ability to function." â€” F. Scott Fitzgerald

One of the most innovative aspects of our research assistant system is its use of multiple AI analyst personas, each bringing a different perspective to the research topic. This chapter explores how we implement this multi-perspective approach, from defining the analyst model to generating diverse personas that explore different aspects of the research topic.

## Defining the Analyst Model

At the core of our multi-perspective approach is the `Analyst` model, which defines the structure of each analyst persona:

```python
class Analyst(BaseModel):
    affiliation: str = Field(
        description="Primary affiliation of the analyst.",
    )
    name: str = Field(
        description="Name of the analyst."
    )
    role: str = Field(
        description="Role of the analyst in the context of the topic.",
    )
    description: str = Field(
        description="Description of the analyst focus, concerns, and motives.",
    )
    @property
    def persona(self) -> str:
        return f"Name: {self.name}\nRole: {self.role}\nAffiliation: {self.affiliation}\nDescription: {self.description}\n"
```

This model captures several key aspects of an analyst's identity:

1. **Affiliation**: The organization or institution the analyst is associated with
2. **Name**: A human-like identifier for the analyst
3. **Role**: The analyst's professional role in relation to the topic
4. **Description**: A more detailed explanation of the analyst's focus and perspective

The `Field` constructor includes descriptions that serve as guidance for the LLM when generating analyst personas. These descriptions help ensure that the generated analysts have appropriate and diverse attributes.

The `persona` property formats the analyst's information for use in prompts, encapsulating this formatting logic in the model itself for consistency.

## Implementing the Perspectives Model

To manage collections of analysts, we define a `Perspectives` model:

```python
class Perspectives(BaseModel):
    analysts: List[Analyst] = Field(
        description="Comprehensive list of analysts with their roles and affiliations.",
    )
```

This model is used with LangChain's structured output functionality to ensure that the LLM generates a properly structured list of analysts:

```python
structured_llm = llm.with_structured_output(Perspectives)
analysts = structured_llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content="Generate the set of analysts.")])
```

## Using Structured Output with LLMs

Structured output is a key technique for ensuring that LLM outputs conform to our expected data structures. The `with_structured_output` method adapts an LLM to produce outputs that match a Pydantic model:

```python
structured_llm = llm.with_structured_output(Perspectives)
```

When this adapted LLM is invoked, it attempts to generate an output that conforms to the `Perspectives` model. If the output doesn't conform (e.g., missing required fields or invalid types), LangChain will attempt to fix the issues or raise an error if the output is fundamentally incompatible with the model.

This structured output approach has several benefits:

1. **Type safety**: Ensuring that outputs have the expected structure
2. **Error handling**: Catching and addressing formatting issues early
3. **Prompt guidance**: Using field descriptions to guide the LLM
4. **Integration**: Seamlessly integrating LLM outputs with our typed state

## Setting Up the Persona Generation Process

The persona generation process is implemented in the `create_analysts` node:

```python
def create_analysts(state: GenerateAnalystsState):
    """ Create analysts """
    
    topic=state['topic']
    max_analysts=state['max_analysts']
    human_analyst_feedback=state.get('human_analyst_feedback', '')
        
    # Enforce structured output
    structured_llm = llm.with_structured_output(Perspectives)

    # System message
    system_message = analyst_instructions.format(topic=topic,
                                              human_analyst_feedback=human_analyst_feedback, 
                                              max_analysts=max_analysts)

    # Generate question 
    analysts = structured_llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content="Generate the set of analysts.")])
    
    # Write the list of analysis to state
    return {"analysts": analysts.analysts}
```

This node takes the research topic, maximum number of analysts, and optional human feedback as inputs, and generates a list of analyst personas as output.

The core of this process is the system prompt, defined separately:

```python
analyst_instructions="""You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:

1. First, review the research topic:
{topic}
        
2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts: 
        
{human_analyst_feedback}
    
3. Determine the most interesting themes based upon documents and / or feedback above.
                    
4. Pick the top {max_analysts} themes.

5. Assign one analyst to each theme."""
```

This prompt instructs the LLM to:

1. Consider the research topic
2. Take into account any human feedback
3. Identify key themes within the topic
4. Select the top N themes (where N is `max_analysts`)
5. Create one analyst persona for each theme

The result is a diverse set of personas, each focused on a different aspect of the research topic.

## Handling Human Feedback in the Workflow

Our system includes a mechanism for incorporating human feedback on the generated analysts:

```python
def human_feedback(state: GenerateAnalystsState):
    """ No-op node that should be interrupted on """
    pass

# Compile with interruption
graph = builder.compile(interrupt_before=['human_feedback'])
```

The `human_feedback` node is a "no-op" (no operation) function that does nothing itself. Its purpose is to serve as an interruption point where the system can pause and wait for human input.

The `interrupt_before` parameter in the `compile` method specifies that execution should pause before the `human_feedback` node, allowing a human to review and potentially modify the generated analysts.

After receiving human feedback, the system uses a conditional edge to determine what to do next:

```python
def initiate_all_interviews(state: ResearchGraphState):
    """ Conditional edge to initiate all interviews via Send() API or return to create_analysts """    

    # Check if human feedback
    human_analyst_feedback=state.get('human_analyst_feedback','approve')
    if human_analyst_feedback.lower() != 'approve':
        # Return to create_analysts
        return "create_analysts"

    # Otherwise kick off interviews in parallel via Send() API
    else:
        topic = state["topic"]
        return [Send("conduct_interview", {"analyst": analyst,
                                         "messages": [HumanMessage(
                                             content=f"So you said you were writing an article on {topic}?"
                                         )
                                                     ]}) for analyst in state["analysts"]]
```

If the human feedback is not "approve" (the default value), the system returns to the `create_analysts` node to generate new analysts based on the feedback. Otherwise, it proceeds with the interviews using the approved analysts.

This human-in-the-loop design allows for iterative refinement of the analyst personas, ensuring that they align with the human's research goals.

## Generating Diverse Perspectives

A key goal of our multi-analyst approach is to generate diverse perspectives on the research topic. The system achieves this in several ways:

### Thematic Division

The system prompt instructs the LLM to identify different themes within the research topic and assign one analyst to each theme. This thematic division ensures that each analyst focuses on a different aspect of the topic.

### Organizational Diversity

By specifying different affiliations for each analyst, the system encourages diversity in organizational perspectives. For example, on a topic like climate change, analysts might come from academia, industry, government, non-profits, etc.

### Role Diversity

Similarly, by specifying different roles for each analyst, the system encourages diversity in professional perspectives. Continuing the climate change example, analysts might include scientists, policy makers, business leaders, activists, etc.

### Motivational Diversity

The detailed description of each analyst's focus, concerns, and motives allows for diversity in value orientations and priorities. Some analysts might prioritize economic considerations, others environmental impact, others social justice, etc.

## Example Analyst Personas

To illustrate how this works in practice, let's consider an example research topic: "Climate change adaptation strategies."

The system might generate analysts like:

1. **Academic Perspective**:
   - Name: Dr. Sarah Chen
   - Affiliation: Stanford University
   - Role: Climate Scientist
   - Description: Focuses on evaluating adaptation strategies based on current climate models and scientific understanding. Concerned with evidence-based approaches and long-term effectiveness.

2. **Economic Perspective**:
   - Name: Michael Rodriguez
   - Affiliation: Global Investment Bank
   - Role: Sustainable Finance Analyst
   - Description: Examines the financial viability and economic impact of adaptation strategies. Concerned with cost-benefit analysis, market incentives, and investment opportunities.

3. **Policy Perspective**:
   - Name: Amara Okafor
   - Affiliation: United Nations Environment Programme
   - Role: Policy Advisor
   - Description: Analyzes adaptation strategies from a governance and implementation perspective. Focused on international cooperation, policy frameworks, and equity considerations.

These diverse personas allow the system to explore the topic from multiple angles, resulting in a more comprehensive and nuanced research report.

## The Interview Initialization Process

Once the analyst personas are generated and approved, the system initializes the interview process for each analyst:

```python
return [Send("conduct_interview", {"analyst": analyst,
                                 "messages": [HumanMessage(
                                     content=f"So you said you were writing an article on {topic}?"
                                 )
                                             ]}) for analyst in state["analysts"]]
```

This code uses the `Send()` API to create a separate interview process for each analyst, passing the analyst persona and an initial message to each process.

The initial message ("So you said you were writing an article on...") serves as a conversation starter, prompting the analyst to begin asking questions about the topic.

## Balancing Diversity and Coherence

While diversity of perspectives is valuable, the system also needs to maintain coherence around the central research topic. Several features help balance diversity and coherence:

### Common Research Topic

All analysts share the same overall research topic, ensuring that their diverse perspectives are applied to a common subject.

### Structured Interview Process

All analysts follow the same structured interview process, with similar patterns of questioning and information retrieval, ensuring a consistent approach despite different focuses.

### Unified Report Structure

The final report integrates insights from all analysts into a coherent whole, with a unified introduction, body, and conclusion, ensuring that the diverse perspectives contribute to a coherent narrative.

## Performance Considerations

Generating high-quality analyst personas is computationally intensive, as it requires the LLM to understand the research topic, identify key themes, and create detailed personas for each theme.

To manage this complexity, the system:

1. Uses a temperature of 0 to ensure deterministic outputs
2. Limits the number of analysts to a manageable number (typically 3-5)
3. Provides clear, structured guidance in the system prompt
4. Allows for human feedback to correct any issues

These measures help ensure that the persona generation process is both efficient and effective.

## Summary

In this chapter, we've explored the process of creating AI analyst personas in our LangGraph research assistant:

1. **Analyst Model**: Defines the structure of each analyst persona with fields for affiliation, name, role, and description
2. **Perspectives Model**: Manages collections of analysts for structured output
3. **Structured Output**: Ensures that LLM outputs conform to our expected data structures
4. **Persona Generation**: Uses a system prompt to guide the LLM in creating diverse personas
5. **Human Feedback**: Allows for iterative refinement of the generated personas
6. **Diverse Perspectives**: Achieves diversity through thematic division and varied affiliations, roles, and motivations
7. **Interview Initialization**: Uses the `Send()` API to create parallel interview processes for each analyst

The multi-analyst approach is a key innovation of our system, allowing for exploration of research topics from multiple perspectives. By generating diverse yet coherent analyst personas, the system can produce research reports that are both comprehensive and nuanced.

In the next chapter, we'll dive deeper into the interview system, exploring how these analyst personas interact with information sources to gather insights on the research topic.
