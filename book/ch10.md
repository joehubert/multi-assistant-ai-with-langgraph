[TOC](ch00_overview.md)

# Chapter 10: Prompting Strategies for Research Assistants

> "The art of asking questions is more valuable than solving problems." â€” Claude Levi-Strauss

Effective prompting is the art of guiding large language models (LLMs) to produce useful, accurate, and relevant outputs. In our research assistant, prompts are the primary interface between the framework and the underlying LLM capabilities. This chapter explores the prompting strategies used throughout our system, from analyst persona generation to report writing.

## Designing Effective System Prompts

System prompts define the role, context, and constraints for an LLM. In our research assistant, we use carefully crafted system prompts for each major function. Let's examine the key principles behind these prompts.

### Clear Role Definition

Each prompt begins with a clear statement of the LLM's role:

```python
analyst_instructions = """You are tasked with creating a set of AI analyst personas."""

question_instructions = """You are an analyst tasked with interviewing an expert to learn about a specific topic."""

answer_instructions = """You are an expert being interviewed by an analyst."""

section_writer_instructions = """You are an expert technical writer."""

report_writer_instructions = """You are a technical writer creating a report on this overall topic:"""
```

This role definition helps the LLM adopt the appropriate "persona" for the task, influencing its tone, expertise level, and perspective. By using different roles for different tasks, we can harness the LLM's ability to adapt its outputs to match the expected characteristics of that role.

### Structured Task Instructions

After defining the role, each prompt provides structured instructions for the task:

```python
"""Follow these instructions carefully:

1. First, review the research topic:
{topic}
        
2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts: 
        
{human_analyst_feedback}
    
3. Determine the most interesting themes based upon documents and / or feedback above.
                    
4. Pick the top {max_analysts} themes.

5. Assign one analyst to each theme."""
```

These instructions follow several key principles:

1. **Numbered Steps**: Breaking the task into clear, sequential steps
2. **Actionable Verbs**: Using direct commands like "review," "examine," "determine"
3. **Specific Goals**: Clearly stating the expected outcome of each step
4. **Parameter Integration**: Using placeholders for dynamic content

This structured approach guides the LLM through a complex reasoning process, ensuring that it considers all relevant factors in the correct order.

### Context Integration

Prompts include placeholders for relevant context:

```python
"""Here is your topic of focus and set of goals: {goals}"""

"""To answer question, use this context:
        
{context}"""

"""4. Make your title engaging based upon the focus area of the analyst: 
{focus}"""
```

These placeholders are filled with relevant information from the state:

```python
system_message = question_instructions.format(goals=analyst.persona)
system_message = answer_instructions.format(goals=analyst.persona, context=context)
system_message = section_writer_instructions.format(focus=analyst.description)
```

This dynamic context integration ensures that the LLM has access to all the information it needs to perform its task effectively. By focusing on relevant context, we avoid overwhelming the LLM with irrelevant information that might dilute its focus.

### Constraint Specification

Prompts include explicit constraints to guide the LLM's outputs:

```python
"""1. Use only the information provided in the context. 
        
2. Do not introduce external information or make assumptions beyond what is explicitly stated in the context."""

"""Aim for approximately 400 words maximum"""

"""Target around 100 words"""
```

These constraints serve several purposes:

1. **Factual Grounding**: Ensuring outputs are based on provided information
2. **Length Control**: Keeping outputs concise and focused
3. **Format Adherence**: Ensuring consistent output structure

By explicitly stating these constraints, we help the LLM understand the boundaries of acceptable outputs, reducing the likelihood of hallucinations or irrelevant content.

## Structured Output for Consistency

Our system uses structured output to ensure consistent, parseable responses from the LLM. This approach is particularly important for outputs that need to conform to specific data structures.

### Pydantic Models for Output Structure

We define Pydantic models for structured outputs:

```python
class Analyst(BaseModel):
    affiliation: str = Field(
        description="Primary affiliation of the analyst.",
    )
    name: str = Field(
        description="Name of the analyst."
    )
    role: str = Field(
        description="Role of the analyst in the context of the topic.",
    )
    description: str = Field(
        description="Description of the analyst focus, concerns, and motives.",
    )

class Perspectives(BaseModel):
    analysts: List[Analyst] = Field(
        description="Comprehensive list of analysts with their roles and affiliations.",
    )
```

These models define the expected structure of the output, with field descriptions that guide the LLM in generating appropriate content for each field.

### Adapting LLMs for Structured Output

We adapt the LLM to produce structured outputs using LangChain's `with_structured_output` method:

```python
structured_llm = llm.with_structured_output(Perspectives)
analysts = structured_llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content="Generate the set of analysts.")])
```

This adaptation ensures that the LLM's output conforms to the specified Pydantic model, with appropriate content for each field. If the output doesn't conform, LangChain will attempt to fix the issues or raise an error.

### Benefits of Structured Output

The structured output approach has several advantages:

1. **Type Safety**: Ensuring outputs have the expected structure
2. **Field Validation**: Checking that field values meet any constraints
3. **Ease of Integration**: Seamlessly integrating LLM outputs with typed state
4. **Consistent Format**: Ensuring uniform structure across multiple invocations

By using structured output for key components like analyst personas, we increase the reliability and consistency of our research assistant.

## Managing Source Citations

Proper citation of sources is crucial for research. Our prompts include detailed instructions for citation management:

```python
"""3. The context contain sources at the topic of each individual document.

4. Include these sources your answer next to any relevant statements. For example, for source # 1 use [1]. 

5. List your sources in order at the bottom of your answer. [1] Source 1, [2] Source 2, etc"""

"""6. In the Sources section:
- Include all sources used in your report
- Provide full links to relevant websites or specific document paths
- Separate each source by a newline. Use two spaces at the end of each line to create a newline in Markdown."""
```

These instructions ensure consistent citation throughout the research process, from expert answers to report sections.

### Document Format for Source Attribution

We use a structured document format that includes source information:

```python
formatted_search_docs = "\n\n---\n\n".join(
    [
        f'<Document href="{doc["url"]}"/>\n{doc["content"]}\n</Document>'
        for doc in search_docs
    ]
)
```

This format makes it easy for the LLM to identify and cite sources when generating expert answers.

### Source Consolidation

Our report writer prompt includes instructions for consolidating sources:

```python
"""7. Be sure to combine sources. For example this is not correct:

[3] https://ai.meta.com/blog/meta-llama-3-1/
[4] https://ai.meta.com/blog/meta-llama-3-1/

There should be no redundant sources. It should simply be:

[3] https://ai.meta.com/blog/meta-llama-3-1/"""
```

This consolidation ensures that the final report has a clean, non-redundant source list.

## Balancing Exploration and Focus

Research involves a balance between exploration (gathering diverse information) and focus (addressing specific questions). Our prompts are designed to strike this balance.

### Exploration in Analyst Questions

The question generation prompt encourages exploration:

```python
"""Your goal is boil down to interesting and specific insights related to your topic.

1. Interesting: Insights that people will find surprising or non-obvious.
        
2. Specific: Insights that avoid generalities and include specific examples from the expert."""
```

This guidance encourages analysts to seek novel, specific information rather than general knowledge.

### Focus in Expert Answers

Conversely, the expert answer prompt emphasizes focus:

```python
"""1. Use only the information provided in the context. 
        
2. Do not introduce external information or make assumptions beyond what is explicitly stated in the context."""
```

This constraint ensures that expert answers stay grounded in the retrieved information, avoiding speculation or hallucination.

### Balancing Mechanisms

Several mechanisms help balance exploration and focus:

1. **Turn-Based Structure**: Each analyst can ask multiple questions, allowing for iterative refinement
2. **Query Generation**: Search queries are derived from the specific questions asked
3. **Context Accumulation**: Context grows throughout the interview, enabling deeper exploration
4. **Persona-Driven Questions**: Each analyst focuses on different aspects of the topic

This balanced approach leads to comprehensive yet focused research outputs.

## Tone and Style Considerations

The tone and style of our prompts influence the quality and character of the LLM's outputs. Several considerations guide our prompt design:

### Professional Tone

Our prompts consistently use a professional, formal tone appropriate for research:

```python
"""You are an expert technical writer."""

"""Your task is to create a short, easily digestible section of a report based on a set of source documents."""
```

This professional tone sets expectations for similarly professional outputs.

### Clear, Direct Instructions

Instructions are expressed clearly and directly:

```python
"""First, review the research topic:"""

"""Determine the most interesting themes based upon documents and / or feedback above."""
```

This clarity helps the LLM understand exactly what is expected without ambiguity.

### Structured Formatting Guidance

Prompts include specific formatting instructions:

```python
"""Create a report structure using markdown formatting:
- Use ## for the section title
- Use ### for sub-section headers"""

"""a. Title (## header)
b. Summary (### header)
c. Sources (### header)"""
```

These formatting guidelines ensure consistent, readable outputs across all components of the research process.

## Chain-of-Thought Prompting

For complex reasoning tasks, our prompts use a chain-of-thought approach, breaking the task into explicit reasoning steps:

```python
"""1. First, review the research topic:
{topic}
        
2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts: 
        
{human_analyst_feedback}
    
3. Determine the most interesting themes based upon documents and / or feedback above.
                    
4. Pick the top {max_analysts} themes.

5. Assign one analyst to each theme."""
```

This step-by-step guidance helps the LLM develop a logical reasoning process, leading to more thoughtful and consistent outputs.

### Benefits of Chain-of-Thought

The chain-of-thought approach has several advantages:

1. **Transparent Reasoning**: The LLM's reasoning process becomes more transparent
2. **Error Reduction**: Breaking complex tasks into steps reduces reasoning errors
3. **Comprehensive Consideration**: Ensuring all relevant factors are considered
4. **Ordered Processing**: Ensuring information is processed in a logical sequence

By guiding the LLM through a structured reasoning process, we improve the quality and reliability of its outputs.

## Persona Adaptation Prompting

One of the most powerful aspects of our prompting strategy is persona adaptation, where the LLM adopts different personas for different tasks:

```python
"""You are an analyst tasked with interviewing an expert to learn about a specific topic."""

"""You are an expert being interviewed by an analyst."""

"""You are an expert technical writer."""
```

These persona-based prompts leverage the LLM's ability to adapt its outputs to match expected characteristics of different roles.

### Character Consistency

To maintain character consistency, prompts include explicit reminders:

```python
"""Remember to stay in character throughout your response, reflecting the persona and goals provided to you."""
```

This reminder helps the LLM maintain a consistent voice and perspective throughout its responses.

### Analyst Persona Integration

For analyst questions, we integrate the specific analyst persona:

```python
system_message = question_instructions.format(goals=analyst.persona)
```

This integration ensures that the questions reflect the analyst's specific focus and perspective, enhancing the diversity of the research outputs.

## Summary

In this chapter, we've explored the prompting strategies used in our LangGraph research assistant:

1. **System Prompt Design**: Clear role definition, structured instructions, context integration, and constraint specification
2. **Structured Output**: Using Pydantic models to ensure consistent, parseable responses
3. **Citation Management**: Detailed instructions for proper source attribution
4. **Exploration vs. Focus**: Balancing broad information gathering with specific inquiry
5. **Tone and Style**: Professional language with clear, direct instructions
6. **Chain-of-Thought**: Breaking complex tasks into explicit reasoning steps
7. **Persona Adaptation**: Leveraging the LLM's ability to adopt different roles

Effective prompting is both an art and a science, requiring a deep understanding of LLM capabilities and limitations. By carefully crafting prompts that guide the LLM through complex reasoning processes, we create a research assistant that produces high-quality, reliable, and diverse outputs.

In the next chapter, we'll explore error handling and robustness, examining how our system deals with unexpected outputs and failures in the research process.

[Continue...](ch11.md)
