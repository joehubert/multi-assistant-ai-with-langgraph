# Chapter 9: Managing State Across Sub-Graphs

> "In nature we never see anything isolated, but everything in connection with something else which is before it, beside it, under it and over it." — Johann Wolfgang von Goethe

One of the most powerful aspects of LangGraph is its ability to create nested graphs—graphs within graphs—that allow for modular, reusable components. However, this nesting introduces the challenge of managing state across different levels of the graph hierarchy. This chapter explores how our research assistant handles state passing between parent and child graphs, and how it aggregates results from parallel executions.

## Nested State Graph Architecture

Our research assistant uses a nested graph architecture with two main levels:

1. **Outer Graph**: Manages the overall research process, including analyst generation, parallel interview orchestration, and report generation
2. **Inner Graph**: Manages the interview process for each analyst, including question generation, information retrieval, answer generation, and section writing

This nested structure is implemented by adding the compiled inner graph as a node in the outer graph:

```python
# Compile the inner graph
interview_builder = StateGraph(InterviewState)
# ... define inner graph nodes and edges ...
interview_graph = interview_builder.compile()

# Add the inner graph as a node in the outer graph
builder = StateGraph(ResearchGraphState)
builder.add_node("conduct_interview", interview_graph)
```

This architecture provides several benefits:

1. **Modularity**: The interview process is encapsulated as a reusable component
2. **Separation of Concerns**: Each graph focuses on its specific level of the workflow
3. **Parallelization**: The inner graph can be executed multiple times in parallel
4. **Maintainability**: Changes to one graph don't necessarily affect the other

However, this nesting also requires careful management of state across graph boundaries.

## Passing State Between Parent and Child Graphs

When a parent graph invokes a child graph, it needs to provide the child with an initial state. In our implementation, this happens in the `initiate_all_interviews` function:

```python
def initiate_all_interviews(state: ResearchGraphState):
    # ...
    return [Send("conduct_interview", {"analyst": analyst,
                                     "messages": [HumanMessage(
                                         content=f"So you said you were writing an article on {topic}?"
                                     )
                                                 ]}) for analyst in state["analysts"]]
```

This function creates an initial state for each interview instance, containing:

1. **Analyst**: The specific analyst persona for this interview
2. **Messages**: An initial message to start the conversation

The `Send()` API passes this initial state to the interview graph, allowing it to begin with the necessary context.

### State Type Compatibility

For state passing to work correctly, the child graph's state type must be compatible with the initial state provided by the parent. In our case:

```python
class InterviewState(MessagesState):
    max_num_turns: int # Number turns of conversation
    context: Annotated[list, operator.add] # Source docs
    analyst: Analyst # Analyst asking questions
    interview: str # Interview transcript
    sections: list # Final key we duplicate in outer state for Send() API
```

The initial state provided by `initiate_all_interviews` includes the `analyst` and `messages` fields, which are sufficient to start the interview process. The remaining fields (`context`, `interview`, and `sections`) are populated during the interview.

### Default Values and Optional Fields

To handle cases where not all fields are provided in the initial state, we use several strategies:

1. **Optional Get**: Using the `get` method with default values

```python
max_num_turns = state.get('max_num_turns', 2)
```

This pattern provides a default value (2) if the `max_num_turns` field isn't in the initial state.

2. **Initialize in First Node**: Some fields are initialized by the first node in the graph

```python
def generate_question(state: InterviewState):
    # ...
    return {"messages": [question]}
```

The `messages` field is updated by the first node, ensuring it exists for subsequent nodes.

3. **Accumulation Fields**: For fields that accumulate values, we initialize them as empty when first accessed

```python
context: Annotated[list, operator.add]
```

The `operator.add` annotation ensures that if `context` doesn't exist, it's treated as an empty list and combined with the new values.

## Reducing Multiple Outputs to a Single State

When a child graph completes, its final state needs to be integrated back into the parent state. In our implementation, this happens through the `sections` field:

```python
# In the interview graph
def write_section(state: InterviewState):
    # ...
    return {"sections": [section.content]}

# In the outer graph
class ResearchGraphState(TypedDict):
    # ...
    sections: Annotated[list, operator.add]
```

The `sections` field in `InterviewState` is used to store the final output of each interview (a report section). When the interview completes, this section is added to the `sections` field in `ResearchGraphState` through the `operator.add` annotation.

### Annotated Fields for Aggregation

The key to this aggregation is the `Annotated` type with an operator:

```python
from typing import Annotated
import operator

sections: Annotated[list, operator.add]
```

This annotation tells LangGraph how to combine values from multiple executions of the same node. The `operator.add` function is used to concatenate lists, which is perfect for collecting sections from multiple interviews.

### Aggregation Process

The aggregation process works as follows:

1. Each interview generates a section and stores it in its `sections` field
2. When the interview completes, the value of its `sections` field is returned to the parent graph
3. The parent graph uses the `operator.add` function to add this value to its own `sections` field
4. This process repeats for each parallel interview
5. Once all interviews complete, the parent's `sections` field contains all the generated sections

This aggregation enables the parallel execution of multiple interviews while ensuring that all their outputs are collected for the final report.

## Managing State Evolution During Interviews

The interview process involves a complex evolution of state as the conversation progresses. Let's trace how the state evolves through a typical interview:

1. **Initial State**:
   ```python
   {
       "analyst": analyst_persona,
       "messages": [initial_message]
   }
   ```

2. **After Question Generation**:
   ```python
   {
       "analyst": analyst_persona,
       "messages": [initial_message, analyst_question]
   }
   ```

3. **After Information Retrieval**:
   ```python
   {
       "analyst": analyst_persona,
       "messages": [initial_message, analyst_question],
       "context": [retrieved_information]
   }
   ```

4. **After Answer Generation**:
   ```python
   {
       "analyst": analyst_persona,
       "messages": [initial_message, analyst_question, expert_answer],
       "context": [retrieved_information]
   }
   ```

5. **After Multiple Turns**:
   ```python
   {
       "analyst": analyst_persona,
       "messages": [initial_message, analyst_question_1, expert_answer_1, ..., analyst_question_n, expert_answer_n],
       "context": [retrieved_information_1, ..., retrieved_information_n]
   }
   ```

6. **After Interview Completion**:
   ```python
   {
       "analyst": analyst_persona,
       "messages": [all_messages],
       "context": [all_retrieved_information],
       "interview": "formatted_transcript",
       "sections": [generated_section]
   }
   ```

At each step, the state grows to include more information, with the final state containing the complete conversation history, all retrieved information, and the generated report section.

## State Isolation Between Parallel Executions

When running multiple interviews in parallel, it's crucial that each interview has its own isolated state. LangGraph ensures this isolation through its `Send()` API:

```python
return [Send("conduct_interview", {"analyst": analyst, ...}) for analyst in state["analysts"]]
```

This code creates a separate state for each analyst, ensuring that the interviews don't interfere with each other. Each interview operates on its own state, with its own conversation history, context, and section.

This isolation is particularly important for our research assistant, as it allows each analyst to pursue its own line of questioning without being influenced by other analysts. The result is a diverse set of perspectives that can be integrated in the final report.

## Managing Completions and Interruptions

LangGraph provides mechanisms for managing both completions (when a graph reaches its `END` node) and interruptions (when a graph pauses at an interruption point). Our implementation uses both:

### Completions

When the inner (interview) graph completes, its final state is returned to the outer graph. The `sections` field from this state is added to the outer graph's `sections` field through the `operator.add` annotation.

Once all interviews complete, the outer graph continues to the report generation phase, using the collected sections to generate a comprehensive report.

### Interruptions

The outer graph includes an interruption point before the `human_feedback` node:

```python
graph = builder.compile(interrupt_before=['human_feedback'])
```

When the graph reaches this point, execution pauses and control returns to the calling code. The caller can then examine the current state (e.g., review the generated analysts), modify it (e.g., provide feedback), and resume execution.

This interruption mechanism enables human-in-the-loop control without requiring changes to the graph structure.

## Cross-Graph Data Access Patterns

Our implementation includes several patterns for accessing data across graph boundaries:

### Parent-to-Child Data Passing

The parent graph passes data to the child graph through the initial state:

```python
return [Send("conduct_interview", {"analyst": analyst, ...}) for analyst in state["analysts"]]
```

This pattern allows the parent to provide context (the analyst persona and initial message) to the child.

### Child-to-Parent Result Returning

The child graph returns data to the parent through its final state, which is integrated into the parent's state:

```python
def write_section(state: InterviewState):
    # ...
    return {"sections": [section.content]}
```

This pattern allows the child to provide results (the generated section) to the parent.

### Cross-Graph Field Alignment

The child and parent graphs have aligned field names to facilitate data transfer:

```python
# In InterviewState
sections: list

# In ResearchGraphState
sections: Annotated[list, operator.add]
```

This alignment ensures that data flows smoothly between graphs without requiring field name mapping or translation.

## Performance Considerations for Nested Graphs

Nested graphs introduce additional complexity, which can impact performance. Our implementation includes several optimizations:

### Minimizing State Size

We minimize the size of the state passed between graphs by including only the necessary fields:

```python
return [Send("conduct_interview", {"analyst": analyst, "messages": [initial_message]}) for analyst in state["analysts"]]
```

This reduces the overhead of state serialization and transfer.

### Efficient Result Aggregation

We use efficient aggregation mechanisms (`operator.add`) to combine results from parallel executions:

```python
sections: Annotated[list, operator.add]
```

This avoids the need for complex reduction operations.

### Targeted Field Updates

Each node returns only the fields it needs to update:

```python
return {"sections": [section.content]}
```

This minimizes the amount of state that needs to be processed and updated.

## Common Patterns and Anti-Patterns

Based on our implementation, we can identify several patterns and anti-patterns for managing state across sub-graphs:

### Effective Patterns

1. **Field Alignment**: Aligning field names between parent and child graphs
2. **Minimal Initial State**: Passing only the necessary fields to child graphs
3. **Annotated Aggregation**: Using `Annotated` fields with appropriate operators for result aggregation
4. **Isolated Execution**: Ensuring each parallel execution has its own isolated state
5. **Targeted Updates**: Each node returns only the fields it modifies

### Anti-Patterns to Avoid

1. **Deep State Nesting**: Passing complex nested state structures between graphs
2. **Global State**: Relying on shared global state between parent and child graphs
3. **Manual Aggregation**: Implementing custom aggregation logic instead of using `Annotated` fields
4. **Fixed State Assumption**: Assuming all fields will always be present in the state
5. **Excessive Field Duplication**: Duplicating large fields across parent and child graphs

By following the effective patterns and avoiding the anti-patterns, we can create efficient and maintainable nested graph architectures.

## Summary

In this chapter, we've explored how our LangGraph research assistant manages state across sub-graphs:

1. **Nested Architecture**: Using a two-level graph structure with outer (research) and inner (interview) graphs
2. **State Passing**: Transferring initial state from parent to child graphs
3. **State Compatibility**: Ensuring child graph state types are compatible with provided initial state
4. **Default Values**: Handling missing fields with default values and optional gets
5. **Result Reduction**: Aggregating results from parallel executions using `Annotated` fields
6. **State Evolution**: Tracing how state evolves through the interview process
7. **State Isolation**: Ensuring each parallel execution has its own isolated state
8. **Completions and Interruptions**: Managing graph termination and pause points
9. **Cross-Graph Access**: Patterns for accessing data across graph boundaries
10. **Performance Considerations**: Optimizing state transfer and aggregation

Effective state management across sub-graphs is crucial for building modular, reusable components in LangGraph. By understanding the flow of information between parent and child graphs, we can create complex workflows that remain maintainable and efficient.

In the next chapter, we'll explore prompting strategies for research assistants, examining how we design effective system prompts that guide LLMs through the research process.
